{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['infos', 'metadata'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "pkl_file = 'data/nuscenes-mini/nuscenes_infos_val.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    temporal_infos = pickle.load(f)\n",
    "\n",
    "temporal_infos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lidar_path', 'token', 'sweeps', 'cams', 'lidar2ego_translation', 'lidar2ego_rotation', 'ego2global_translation', 'ego2global_rotation', 'timestamp', 'gt_boxes', 'gt_names', 'gt_velocity', 'num_lidar_pts', 'num_radar_pts', 'valid_flag'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_infos['infos'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_path', 'type', 'sample_data_token', 'sensor2ego_translation', 'sensor2ego_rotation', 'ego2global_translation', 'ego2global_rotation', 'timestamp', 'sensor2lidar_rotation', 'sensor2lidar_translation', 'cam_intrinsic'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_infos['infos'][0]['cams']['CAM_FRONT'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.985793, 0.0, 1.84019]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_infos['infos'][0]['lidar2ego_translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/miniconda3/envs/streampetr/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyquaternion import Quaternion\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils import splits\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import mmcv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_egopose_to_matrix_numpy(rotation, translation):\n",
    "    transformation_matrix = np.zeros((4, 4), dtype=np.float32)\n",
    "    transformation_matrix[:3, :3] = rotation\n",
    "    transformation_matrix[:3, 3] = translation\n",
    "    transformation_matrix[3, 3] = 1.0\n",
    "    return transformation_matrix\n",
    "\n",
    "def invert_matrix_egopose_numpy(egopose):\n",
    "    \"\"\" Compute the inverse transformation of a 4x4 egopose numpy matrix.\"\"\"\n",
    "    inverse_matrix = np.zeros((4, 4), dtype=np.float32)\n",
    "    rotation = egopose[:3, :3]\n",
    "    translation = egopose[:3, 3]\n",
    "    inverse_matrix[:3, :3] = rotation.T\n",
    "    inverse_matrix[:3, 3] = -np.dot(rotation.T, translation)\n",
    "    inverse_matrix[3, 3] = 1.0\n",
    "    return inverse_matrix\n",
    "\n",
    "def _get_rot(h):\n",
    "        return torch.Tensor(\n",
    "            [\n",
    "                [np.cos(h), np.sin(h)],\n",
    "                [-np.sin(h), np.cos(h)],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def _img_transform(img, resize, resize_dims, crop, flip, rotate):\n",
    "        ida_rot = torch.eye(2)\n",
    "        ida_tran = torch.zeros(2)\n",
    "        # adjust image\n",
    "       \n",
    "        \n",
    "        img = img.resize(resize_dims)\n",
    "        img = img.crop(crop)\n",
    "        if flip:\n",
    "            img = img.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "        img = img.rotate(rotate)\n",
    "\n",
    "        # post-homography transformation\n",
    "        ida_rot *= resize\n",
    "        ida_tran -= torch.Tensor(crop[:2])\n",
    "        if flip:\n",
    "            A = torch.Tensor([[-1, 0], [0, 1]])\n",
    "            b = torch.Tensor([crop[2] - crop[0], 0])\n",
    "            ida_rot = A.matmul(ida_rot)\n",
    "            ida_tran = A.matmul(ida_tran) + b\n",
    "        A = _get_rot(rotate / 180 * np.pi)\n",
    "        b = torch.Tensor([crop[2] - crop[0], crop[3] - crop[1]]) / 2\n",
    "        b = A.matmul(-b) + b\n",
    "        ida_rot = A.matmul(ida_rot)\n",
    "        ida_tran = A.matmul(ida_tran) + b\n",
    "        ida_mat = torch.eye(3)\n",
    "        ida_mat[:2, :2] = ida_rot\n",
    "        ida_mat[:2, 2] = ida_tran\n",
    "        return img, ida_mat\n",
    "\n",
    "val_scenes = splits.mini_val\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='data/nuscenes/', verbose=False)\n",
    "\n",
    "scene_name = 'scene-0103'\n",
    "scene = next(scene for scene in nusc.scene if scene['name'] == scene_name) \n",
    "scene_token = scene['token']\n",
    "\n",
    "sample = nusc.get('sample', scene['first_sample_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==intrinsic==\n",
      " [[624.98146404   0.         412.68840227   0.        ]\n",
      " [  0.         624.98146404 101.27408193   0.        ]\n",
      " [  0.           0.           1.           0.        ]\n",
      " [  0.           0.           0.           1.        ]]\n",
      "==extrinsic==\n",
      " [[-0.3820134  -0.92305064 -0.04520244  0.08872822]\n",
      " [ 0.01385406  0.04318667 -0.998971   -0.29866916]\n",
      " [ 0.92405295 -0.38224655 -0.00370989 -0.46464512]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "==lidar2img==\n",
      " [[ 1.42594637e+02 -7.34638261e+02 -2.97817150e+01 -1.36300159e+02]\n",
      " [ 1.02241144e+02 -1.17207993e+01 -6.24714065e+02 -2.33719196e+02]\n",
      " [ 9.24052954e-01 -3.82246554e-01 -3.70989158e-03 -4.64645118e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "==ego_pose==\n",
      " [[-4.8142377e-01  8.7494826e-01  5.1929332e-02  6.0100812e+02]\n",
      " [-8.7646019e-01 -4.8009163e-01 -3.6461607e-02  1.6469954e+03]\n",
      " [-6.9711814e-03 -6.3067481e-02  9.9798489e-01  1.8232931e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "intrinsic_arr = []\n",
    "extrinsic_arr = []\n",
    "lidar2img_arr = []\n",
    "filename_arr = []\n",
    "img_arr = []\n",
    "\n",
    "mean = np.array([103.530, 116.280, 123.675], dtype=np.float32)\n",
    "std = np.array([57.375, 57.120, 58.395], dtype=np.float32)\n",
    "\n",
    "cams = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n",
    "\n",
    "sd_rec_l = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "\n",
    "cs_record_l = nusc.get('calibrated_sensor', sd_rec_l['calibrated_sensor_token'])\n",
    "\n",
    "pose_record_l = nusc.get('ego_pose', sd_rec_l['ego_pose_token'])\n",
    "\n",
    "# ego pose\n",
    "\n",
    "# cs_record['translation'] -> lidar2ego_translation\n",
    "# cs_record['rotation'] -> lidar2ego_rotation\n",
    "# pose_record['translation'] -> ego2global_translation\n",
    "# pose_record['rotation'] -> ego2global_rotation\n",
    "\n",
    "e2g_rotation = Quaternion(pose_record_l['rotation']).rotation_matrix\n",
    "e2g_translation = pose_record_l['translation']\n",
    "l2e_rotation = Quaternion(cs_record_l['rotation']).rotation_matrix\n",
    "l2e_translation = cs_record_l['translation']\n",
    "e2g_matrix = convert_egopose_to_matrix_numpy(e2g_rotation, e2g_translation)\n",
    "l2e_matrix = convert_egopose_to_matrix_numpy(l2e_rotation, l2e_translation)\n",
    "\n",
    "ego_pose = e2g_matrix @ l2e_matrix\n",
    "ego_pose_inv = invert_matrix_egopose_numpy(ego_pose)\n",
    "timestamp = sd_rec_l['timestamp'] / 1e6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lidar2img & intrinsic & extrinsic\n",
    "for cam in cams:\n",
    "\n",
    "    cam_front_token = sample['data'][cam]\n",
    "\n",
    "    # 使用 token 获取 sample_data 记录\n",
    "    sd_rec_c = nusc.get('sample_data', cam_front_token)\n",
    "\n",
    "\n",
    "\n",
    "    # 获取摄像头的校准数据\n",
    "    cs_record_c = nusc.get('calibrated_sensor', sd_rec_c['calibrated_sensor_token'])\n",
    "\n",
    "    pose_record_c = nusc.get('ego_pose', sd_rec_c['ego_pose_token'])\n",
    "\n",
    "\n",
    "\n",
    "    # lidar\n",
    "    l2e_t = np.array(cs_record_l['translation'])\n",
    "    e2g_t = np.array(pose_record_l['translation'])\n",
    "    l2e_r = np.array(cs_record_l['rotation'])\n",
    "    e2g_r = np.array(pose_record_l['rotation'])\n",
    "\n",
    "    # cam\n",
    "    l2e_t_s = np.array(cs_record_c['translation'])\n",
    "    e2g_t_s = np.array(pose_record_c['translation'])\n",
    "    l2e_r_s = np.array(cs_record_c['rotation'])\n",
    "    e2g_r_s = np.array(pose_record_c['rotation'])\n",
    "\n",
    "\n",
    "    l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n",
    "    e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n",
    "\n",
    "    l2e_r_s_mat = Quaternion(l2e_r_s).rotation_matrix\n",
    "    e2g_r_s_mat = Quaternion(e2g_r_s).rotation_matrix\n",
    "\n",
    "    R = (l2e_r_s_mat.T @ e2g_r_s_mat.T) @ (\n",
    "            np.linalg.inv(e2g_r_mat).T @ np.linalg.inv(l2e_r_mat).T)\n",
    "    T = (l2e_t_s @ e2g_r_s_mat.T + e2g_t_s) @ (\n",
    "        np.linalg.inv(e2g_r_mat).T @ np.linalg.inv(l2e_r_mat).T)\n",
    "    T -= e2g_t @ (np.linalg.inv(e2g_r_mat).T @ np.linalg.inv(l2e_r_mat).T\n",
    "                    ) + l2e_t @ np.linalg.inv(l2e_r_mat).T\n",
    "\n",
    "    cam2lidar_r = R.T\n",
    "    cam2lidar_t = T\n",
    "\n",
    "\n",
    "    cam2lidar_rt = convert_egopose_to_matrix_numpy(cam2lidar_r, cam2lidar_t)\n",
    "    lidar2cam_rt = invert_matrix_egopose_numpy(cam2lidar_rt)\n",
    "\n",
    "    intrinsic = np.array(cs_record_c['camera_intrinsic'])\n",
    "\n",
    "    viewpad = np.eye(4)\n",
    "    viewpad[:intrinsic.shape[0], :intrinsic.shape[1]] = intrinsic\n",
    "\n",
    "    lidar2img_rt = (viewpad @ lidar2cam_rt)\n",
    "\n",
    "    intrinsic = viewpad\n",
    "    extrinsic = lidar2cam_rt\n",
    "\n",
    "    # LoadImage\n",
    "\n",
    "    img_name = 'data/nuscenes/' + sd_rec_c['filename']\n",
    "    img_ori = Image.fromarray(mmcv.imread(img_name, 'unchanged'))\n",
    "  \n",
    "  \n",
    "    # ResizeCropFlipRotImage class call\n",
    "\n",
    "    # img_ori = Image.fromarray(np.uint8(np.zeros((900, 1600, 3))))\n",
    "    img, ida_mat = _img_transform(\n",
    "                    img_ori,\n",
    "                    resize=0.5,\n",
    "                    resize_dims=(800, 450),\n",
    "                    crop=(0, 130, 800, 450),\n",
    "                    flip=False,\n",
    "                    rotate=0,\n",
    "                )\n",
    "    intrinsic[:3, :3] = ida_mat @ intrinsic[:3, :3]\n",
    "\n",
    "    lidar2img = intrinsic @ extrinsic\n",
    "\n",
    "    #===================================\n",
    "    # PadImage\n",
    "\n",
    "    img = mmcv.impad_to_multiple(np.array(img), 32, pad_val=0)\n",
    "\n",
    "    # NormalizeImage\n",
    "    \n",
    "    img = mmcv.imnormalize(img, mean, std, False)\n",
    "\n",
    "    intrinsic_arr.append(intrinsic)\n",
    "    extrinsic_arr.append(extrinsic)\n",
    "    lidar2img_arr.append(lidar2img)\n",
    "    filename_arr.append('data/nuscenes/' + sd_rec_c['filename'])\n",
    "    img_arr.append(img.transpose(2, 0, 1))\n",
    "    \n",
    "img_arr = np.stack(img_arr)\n",
    "# img_arr = np.stack([mmcv.imread(name, 'unchanged') for name in filename_arr], axis=-1)\n",
    "\n",
    "# padded_img = [mmcv.impad_to_multiple(img,\n",
    "#                                 32, pad_val=0) for img in img_arr]\n",
    "print('==intrinsic==\\n', intrinsic)\n",
    "print('==extrinsic==\\n', extrinsic)\n",
    "print('==lidar2img==\\n', lidar2img)\n",
    "print('==ego_pose==\\n', ego_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 320, 800)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(img_arr[0])\n",
    "# plt.show()\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.8142377e-01,  8.7494826e-01,  5.1929332e-02,  6.0100812e+02],\n",
       "       [-8.7646019e-01, -4.8009163e-01, -3.6461607e-02,  1.6469954e+03],\n",
       "       [-6.9711814e-03, -6.3067481e-02,  9.9798489e-01,  1.8232931e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ego pose\n",
    "from pyquaternion import Quaternion\n",
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils import splits\n",
    "\n",
    "val_scenes = splits.mini_val\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='data/nuscenes/', verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "scene_name = 'scene-0103'\n",
    "scene = next(scene for scene in nusc.scene if scene['name'] == scene_name) \n",
    "scene_token = scene['token']\n",
    "\n",
    "sample = nusc.get('sample', scene['first_sample_token'])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streampetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
